# Introduction

Large language models (LLMs) can be trained on a vast number of high-quality code repositories. These models can then be used for a variety of software engineering tasks including code generation. Such models are trained on a large amount high-quality code that has been written by hand. The trained model can then be used to solve software engineering problems. For instance, it can be prompted to generate a custom function in the Python programming language.

A.I. tools can be used for:

- code generation  
- language translation
- debugging assistance
- code navigation  
- writing test code  
- generating documentation  
- parallelizing code
- IDE integration with code completion

## Important Points

- The A.I. tools are not perfect. Think of their output as a starting point that you will validate and modify. Do not think of A.I. generated code as an immediate final solution.
- In order to evaluate the output of an A.I. model you must know the programming language and maybe research domain. For example, if you do not know Python then do not use A.I. generated Python code since you will not be able to validate it.
- If you choose to use A.I. generated code then you are responsible for that code. That is, if the code contained a bug then you take responsibility for the bug.

## Position of the Princeton Information Security Office

Read their position: [ISO on GenAI](https://informationsecurity.princeton.edu/posts/2023/prohibition-university-data-publicly-available-generative-artificial-intelligence-ai)

## Licensing

For licensing issues regarding the use of A.I. generated code, see [LLMs and code assistants on INTERSECT](https://intersect-training.org/software-licensing/07-collaboration/index.html).
